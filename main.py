#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
    Predix.io Catalog Scraper
    ~~~~~~~~~~~~~~~~~~~~~~~~~

    Scrape the Predix.io Catalog and generate an excel file listing
    all the services with detailed information available on it.

    :version: 0.1
    :copyright: 2016 by Mirco Veltri
    :license: GPL, see LICENSE for more details
"""

import os
import sys
import shutil
import signal
import configs  # configuration settings come from configs.py
from utils.webpage_spider import WebPageSpider
from utils.predix_catalog_scraper import PredixCatalogScraper
from utils.excel_file_writer import ExcelFileWriter

OUTPUT_FOLDER = "output"
OUTPUT_FILENAME = "predix-catalog.xlsx"

file_writer = ExcelFileWriter()

def services():
    return "services"

def analytics():
    return "analytics"

catalogs = {
    0: services,
    1: analytics
}

def cleanup():
    """ Removing __pycache_folders and clean """
    ghostdriver_log_file = "ghostdriver.log"
    if os.path.exists(ghostdriver_log_file):
        os.remove(ghostdriver_log_file)

    if os.path.exists("__pycache__"):
        shutil.rmtree("__pycache__")

    if os.path.exists(os.path.join("utils", "__pycache__")):
        shutil.rmtree(os.path.join("utils", "__pycache__"))

    file_writer.close()

def sigint_handler(signum, frame):
    """ Handle CTRL+C in the script """
    cleanup()
signal.signal(signal.SIGINT, sigint_handler)

def main():
    # Create an excel workbook
    file_writer.create_file(OUTPUT_FOLDER, OUTPUT_FILENAME)
    # Create a webpage spider instance
    web_spider = WebPageSpider()

    # Scraping the Services Catalog
    print("\n# Scraping Predix Catalog for 'Services':",
          configs.px_services_catalog_url)
    services_scraper = PredixCatalogScraper(web_spider, catalogs[0](), configs)
    services_scraper.parse()

    file_writer.add_worksheet(catalogs[0]())
    file_writer.set_summary_vars(
        services_scraper.categoriesCounter(), services_scraper.tilesCounter())
    file_writer.write_content(services_scraper.getContent())

    # Scraping the Analytics Catalog
    print("\n# Scraping Predix Catalog for 'Analytics':",
          configs.px_analytics_catalog_url)
    analytics_scraper = PredixCatalogScraper(
        web_spider, catalogs[1](), configs)
    analytics_scraper.parse()
    file_writer.add_worksheet(catalogs[1]())
    file_writer.set_summary_vars(
        analytics_scraper.categoriesCounter(), analytics_scraper.tilesCounter())
    file_writer.write_content(analytics_scraper.getContent())

    # Save and close the Excel file
    print("\n\n* Saving the file...")
    file_writer.close()
    print("\t* '" + os.path.join(OUTPUT_FOLDER, OUTPUT_FILENAME) + "' file saved")

    # Output to shell
    print("\n## Summary for 'Services':")
    print("\t* number of available categories:",
          services_scraper.categoriesCounter())
    print("\t* number of available services:",
          services_scraper.tilesCounter())

    print("\n## Summary for 'Analytics':")
    print("\t* number of available categories:",
          analytics_scraper.categoriesCounter())
    print("\t* number of available services:",
          analytics_scraper.tilesCounter())


if __name__ == "__main__":
    # Run as main program
    main()
    # Removing autogenerated files
    cleanup()
